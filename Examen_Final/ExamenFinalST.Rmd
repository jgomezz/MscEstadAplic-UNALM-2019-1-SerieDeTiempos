---
title: "Exanen Final Serie de Tiempos"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Identificacion 
Se cargan las libs necesarias y se convierten los datos a formato de serie de tiempo.

```{r }
library(fpp2)
library(tseries)
library(urca)
library(forecast)
```

## Identificacion del modelo
##1.- [4.0 puntos] Explique la etapa de identificación del modelo según la metodología Box Jenkins.

En este apartado lo que se hace es:
1.1- Obtener los datos y leerlos como una serie de tiempos
1.2- Graficar los datos y realizar una analisis descriptivo : ACF y PACF
1.3- Se debe evaluar si la serie es estacionaria con las hipotesis, en caso de no serlo se tiene que diferenciar hasta que se vuelvan estacionarias. Se apoya en lo graficos de ACF y PACF para buscar algun relación en las correlaciones (se obtiene los valores p o q ).
1.4- Se elige entre los modelos ARIMA o SARIMA. Tambien en caso el modelo tenga estacionalidad, se usa el modelo SARIMA 

A continuación se procede con lo indicado

1.1- Obtener los datos y leerlos como una serie de tiempos

```{r }
datos = read.table("PN02703BQ.txt",T)
(ingmin = ts(datos, start = c(1985,1), frequency = 4 ) )

```
1.2- Graficar los datos y realizar una analisis descriptivo

Notamos en el grafico ACF, domina la tendencia. En la grafica de lineas hay una tendencia creciente fuerte de ingresos mineros en a partir del año 2005 y luego tiene volatilidad

```{r }
forecast::ggtsdisplay(ingmin,lag = 30)
```

Se observa que la mediana de todos los trimestres son muy similares .

```{r }
boxplot(ingmin ~ cycle(ingmin), col="gold")
```

1.3- Se debe evaluar si la serie es estacionaria con las hipotesis, en caso de no serlo se tiene que diferenciar hasta que se vuelvan estacionarias. Se apoya en lo graficos de ACF y PACF para buscar algun relación en las correlaciones (se obtiene los valores p o q ).


Realizamos pruebas de estacionariedad

```{r }
kpss.test(ingmin)$p.value
```
No es estacionaria
```{r }
adf.test(ingmin)$p.value
```
No es estacionaria

```{r }
ur.df(ingmin)@teststat
```

```{r }
pp.test(ingmin)$p.value
```
No es estacionaria

```{r }
ur.pp(ingmin)@teststat
```
Todas las pruebas de hipotesis arrojan que la serie de tiempo es no estacionaria.

Diferenciamos una vez para buscar estacionarizarla.

```{r}
forecast::ggtsdisplay(diff(ingmin), lag=90)
```
Se obseva que en los graficos de ACF y PACF predomina la estacionalidad, se tiene que cuando d=1, p y q tenes valores distinto de 0.

Se reviso los supuestos de estacionaridad

```{r echo=TRUE}
tseries::kpss.test(diff(ingmin))$p.value
```
Se rechaza la H0 de estacionariedad de la serie.

```{r }
tseries::adf.test(diff(ingmin))$p.value 
```
El pvalue menor que 0.01, se rechaza la H0 de raiz unitaria, de modo que se la estacionariedad de la serie.

```{r }
urca::ur.df(diff(ingmin))@teststat
```
```{r }
tseries::pp.test(diff(ingmin))$p.value 
```
El pvalue menor que 0.01, se rechaza la H0 de raiz unitaria, de modo que se la estacionariedad de la serie.

```{r }
urca::ur.pp(diff(ingmin))@teststat
```
Conclusión parcial: De las 3 pruebas de estacionariedad , 2 nos indican que hay estacionaridad, por lo tanto podemos considerar que realizar la primera diferenciación la serie se vuelve estacionaria. Se procede a generar los correlogramas con una diferenciación:

1.4- Se elige entre los modelos ARIMA o SARIMA. Tambien en caso el modelo tenga estacionalidad, se usa el modelo SARIMA 
Se evalua cual podria ser el modelo propuesto con una diferenciacion

```{r}
auto.arima(ingmin, d = 1, D = 0)

```
Modelo propuesto : ARIMA(0,1,0)(1,0,0)[4]  

Se procede a graficar
```{r}
ggtsdisplay(diff(diff(ingmin),lag=4),lag = 90)

```

```{r}
kpss.test(diff(diff(ingmin),lag=4))$p.value 

```
Es estacionaria
```{r}
adf.test(diff(diff(ingmin),lag=4))$p.value 
```
Es estacionaria
```{r}
ur.df(diff(diff(ingmin),lag=4))@teststat 
```


```{r}
pp.test(diff(diff(ingmin),lag=4))$p.value 
```
Es estacionaria

```{r}
ur.pp(diff(diff(ingmin),lag=4))@teststat
```
Se consigue volver a la serie estacionaria con la segunda diferenciación, falta controlar la estacionalidad, para tal fin nos apoyamos en auto.arima

1.4- Se elige entre los modelos ARIMA o SARIMA. Tambien en caso el modelo tenga estacionalidad, se usa el modelo SARIMA 

```{r}
auto.arima(ingmin, d = 1, D = 1)
```
Modelo propuesto : ARIMA(0,1,0)(1,1,2)[4] 

```{r}
auto.arima(ingmin)
```
Modelo propuesto : (0,1,0)(1,0,0)[4] 

## Modelamiento
2. [2.0 puntos] Estime los parámetros de los modelos tentativos y escriba estos modelos.

Con la evaluación del paso anterior se sugieren los siguientes modelos 
```{r}
mod_1 = Arima(y = ingmin, order = c(0,1,0), seasonal = c(1,0,0))
summary(mod_1)
```


```{r}
mod_2 = Arima(y = ingmin, order = c(0,1,0), seasonal = c(1,1,2))
summary(mod_2)
```


```{r}
mod_3 = Arima(y = ingmin, order = c(1,1,0), seasonal = c(1,0,0))
summary(mod_3)
```

3.- [6.0 puntos] Presente un análisis que permita verificar si el/los modelo(s) es/son adecuado(s) de manera individual (al menos 3 indicadores) y comparativa (use el MAPE en validación cruzada, considerando un tamaño mínimo de entrenamiento de 20 trimestres, y un horizonte de prueba de un año). En base a ello, elija el mejor modelo.

## Diagnostico 

Una vez que tenemos varios modelos tentativos, realizamos pruebas de diagnostico.

```{r}
res1 = residuals(mod_1)
res2 = residuals(mod_2)
res3 = residuals(mod_3)

ggtsdisplay(res1)
```

El modelo 1 muestra un buen comportamiento de residuales: algunas autocorrelaciones estan fuera de las bandas. 
```{r}
ggtsdisplay(res2)
```

El modelo 2 tambien tiene un aceptable comportamiento de residuales,
```{r}
ggtsdisplay(res3)

```
El modelo 3 tambien exhibe un buen comportamiento de residuales: hay pocas autocorrelaciones fuera de las bandas


```{r}
t.test(res1)$p.value
t.test(res2)$p.value
t.test(res3)$p.value

```

Todas los residuales dan resultados satisfactorios respecto a que la media de los residuales de los modelos son significativamente cero

```{r}
shapiro.test(res1)$p.value
shapiro.test(res2)$p.value
shapiro.test(res3)$p.value

```

Ningun modelo supera el test de normalidad de residuales, sin embargo, muestra que ninguno de los modelos prueba estadisticamente al 5% de significancia que los residuales siguen una distribucion normal. Todavia deben hacerse esfuerzos para mejorar los ajustes de los modelos, por ejemplo, incorporando media o drift, para superar este escollo, toda vez que los pronosticos que se hagan con ellos no seran del todo confiables.

Por otro lado, procedemos a emitir indicadores de exactitud de pronosticos:

```{r}
accuracy(forecast(mod_1))
```


```{r}
accuracy(forecast(mod_2))
```


```{r}
accuracy(forecast(mod_3))
```

Segun lo anterior, el modelo 2 logra mejor performance en las 3 medidas de exactitud (MAE, MAPE y MASE).

## Cross Validation

Realizamos una prueb de cross validacion para probar los modelos con datos distintos de los que sirvieron para
construir los modelos.

```{r}

n    = length(ingmin)  # longitud de la serie
k    = 20                # longitud m?nima de la data de entrenamiento (k<n)
ho   = 4                 # longitud de la data de prueba (ho<k<n)
mape1 = mape2 = mape3 = mape4 =  matrix(NA,n-k-ho,ho)
st   = tsp(ingmin)[1]  # inicio de la serie

for(i in 1:(n-k-ho)){
  train   = window(ingmin, 
                   end   = st + k/4 + (i-2)/4)
  test    = window(ingmin, 
                   start = st + k/4 + (i-1)/4,
                   end   = st + k/4 + (i-1)/4 + (ho-1)/4)
  
  modelo1 = Arima(train, order = c(0,1,1), seasonal = c(0,1,1))  
  predi1  = forecast(modelo1,h = ho)                                        
  mape1[i,1:length(test)] = mean(abs((ts(test) - ts(predi1$mean))/ts(test)))*100
  
  modelo2 = Arima(train, order = c(0,1,1), seasonal = c(0,1,2))  
  predi2  = forecast(modelo2,h = ho)                                        
  mape2[i,1:length(test)] = mean(abs((ts(test) - ts(predi2$mean))/ts(test)))*100
  
  modelo3 = Arima(train, order = c(0,1,2), seasonal = c(0,1,1))  
  predi3  = forecast(modelo3,h = ho)                                        
  mape3[i,1:length(test)] = mean(abs((ts(test) - ts(predi3$mean))/ts(test)))*100

  }  

```


```{r}
plot(1:ho, 
     colMeans(sqrt(mape1),na.rm=TRUE), 
     type = "l", 
     lwd  = 2,
     col  = "red", 
     xlab = "horizonte", 
     ylab = "MAPE",
     ylim = c(3.5,3.7))
lines(1:ho, 
      colMeans(sqrt(mape2),na.rm=TRUE), 
      type = "l",
      lwd  = 2,
      col  = "darkblue")
lines(1:ho, 
      colMeans(sqrt(mape3),na.rm=TRUE), 
      type = "l",
      lwd  = 2,
      col  = "springgreen3")
legend("topleft",
       legend = c("ARIMA(0,1,0)(1,0,0)[4]","ARIMA(0,1,0)(1,1,2)[4]","ARIMA(1,1,0)(1,0,0)[4]"),
       col    = c("red","darkblue","springgreen3"),
       lty    = 1,
       lwd    = 2)

```

La grafica de la prueba de cross validation no permite dar un veredicto concluyente de que el mejor modelo es el modelo 2, es decir ARIMA(0,1,0)(1,1,2)[4].

## Prediccion 
4.- [2.0 puntos] Realice la predicción puntual para los años 2019 y 2020 empleando el mejor modelo y en caso sea adecuado, presente la predicción intervalar.


Se calcula la prediccion hasta el Q4 del 2020
```{r}

forecast(mod_2, h = 7)

```

Graficamente:
Se calcula la prediccion hasta el Q4 del 2020

```{r}
autoplot(forecast(mod_2, h = 4))
```

2.0puntos]Justifique si esnecesario considerar un modelo GARCH o basta trabajar según la metodología Box Jenkins.


```{r}
autoplot(ingmin)
```
En el grafico se puede apreciar que hay mucha volatilidad, aunque esto deberia ser analizado por cada año, porque Box Jenkins considera que la varianza es constante, pero vemos que hay una varianza que esta cambiando en cada año, por lo tanto para poder realizar estimaciones en el corto tiempo vendria bien el uso de un modelo GARCH 

